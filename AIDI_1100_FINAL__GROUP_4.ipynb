{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanathdavis/python_test/blob/main/AIDI_1100_FINAL__GROUP_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# <u>**Final Project : Introduction to AI Development**</u>\n",
        "\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "**<u>Group 4</u>** \n",
        "---\n",
        "\n",
        "<u>AIDI_1100</u>\n",
        "---\n",
        "Fenil (ID: 100867001)\n",
        "---\n",
        "Abhishek (ID: '')\n",
        "---\n",
        "Sanath Davis (ID: 100884693)\n",
        "---\n",
        "\n",
        "\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "jmoLf5F0ZXTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preperation\n",
        "\n",
        "\n",
        "*   Installs\n",
        "*   Imports\n",
        "*   Date Range\n",
        "*   Constants\n",
        "\n"
      ],
      "metadata": {
        "id": "uE2yK7sed5iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installs\n",
        "\n",
        "\n",
        "\n",
        "*   StockSymbol\n",
        "*   YFinance\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5N2DM5HJZRih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stocksymbol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzgEXhVpv5MY",
        "outputId": "71e28d6f-97f5-446c-fc37-f7c77c85185a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stocksymbol in /usr/local/lib/python3.8/dist-packages (0.0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezRdiv32PYKs",
        "outputId": "355c85a2-c41b-4cf6-a16c-d12e72dad273"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.8/dist-packages (0.1.90)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "9DS8ImM4aOtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from datetime import date, datetime, timedelta\n",
        "from stocksymbol import StockSymbol\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "6l3D8q-lRi4A"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants\n",
        "We are ignoring stock symbols that are easy to get mistaken"
      ],
      "metadata": {
        "id": "TUIKUOS1aSm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-0gDqb_P_ftb"
      },
      "outputs": [],
      "source": [
        "HUB_URL = 'https://www.1888pressrelease.com'\n",
        "MIN_DATE = '2010-01-07'\n",
        "MAX_DATE = datetime.today().strftime('%Y-%m-%d')\n",
        "LIST_OF_COUNTRIES = ['US', 'CA', 'IN'] \n",
        "# STOCK_SYMBOL_API_KEY = '4bd01ff2-007a-4d1a-8e7e-e7e6c72d3352'\n",
        "#STOCK_SYMBOL_API_KEY = '4290b706-c38d-4b5b-a98e-d5375fe4ed19'\n",
        "STOCK_SYMBOL_API_KEY = '6b1fe6d6-c67d-436d-b976-2a72f18ed463' #https://stock-symbol.herokuapp.com/\n",
        "STOCKS_TO_IGNORE = ['PM', 'V', 'total']\n",
        "#STOCKS_TO_IGNORE = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_date_range():\n",
        "  #@title Select Date Range for Collecting News (Default is past 7 days)\n",
        "  start_date = \"2022-12-01\" #@param {type:\"date\"}\n",
        "  end_date = \"2022-12-01\" #@param {type:\"date\"}\n",
        "  return {\n",
        "      'start_date' : start_date,\n",
        "      'end_date' : end_date\n",
        "      }\n",
        "\n",
        "# start_date = (datetime.today()- timedelta(days=7)).strftime('%Y-%m-%d') #@param {type:\"date\"}\n",
        "# end_date = datetime.today().strftime('%Y-%m-%d') #@param {type:\"date\"}"
      ],
      "metadata": {
        "id": "7F2_rEYHSKmb",
        "cellView": "form"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Scan/Parse/Scrape\n",
        "\n",
        "* Scan a Website for Links within required Time Frame\n",
        "* Parse each news article obtained from the urls\n",
        "* Scap for the required Title and Body of the article "
      ],
      "metadata": {
        "id": "Z-X92qlzb3VU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_all_dates_in_range\n",
        "Get all the different dates in a range of dates"
      ],
      "metadata": {
        "id": "0vDGqQFYaazy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_dates_in_range():  \n",
        "  dates = []\n",
        "  date_range = get_date_range()\n",
        "  def daterange(date1, date2):\n",
        "    for n in range(int ((date2 - date1).days)+1):\n",
        "        yield date1 + timedelta(n)\n",
        "\n",
        "  start_dt = datetime.fromisoformat(date_range['start_date'])\n",
        "  end_dt = datetime.fromisoformat(date_range['end_date'])\n",
        "\n",
        "  for dt in daterange(start_dt, end_dt):\n",
        "      dates.append(dt.strftime(\"%m-%d-%Y\"))\n",
        "\n",
        "  return dates"
      ],
      "metadata": {
        "id": "G2l1SKi-b_VY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Url\n",
        "URL Class which contains soup creator and URL list creator"
      ],
      "metadata": {
        "id": "4Llml1d5aily"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Url:\n",
        "    def __init__(self, url):\n",
        "      self.url = url\n",
        "\n",
        "    def get_soup(self):\n",
        "      url_response = requests.get(self.url, allow_redirects=False)\n",
        "      self.soup = BeautifulSoup(url_response.text, 'html.parser')\n",
        "    \n",
        "    def get_number_of_pages(self):\n",
        "      pagination_block = self.soup.find(\"div\", {\"class\": \"number\"})\n",
        "      if pagination_block:\n",
        "        number_of_pages = len(pagination_block.find_all('li'))\n",
        "        return number_of_pages\n",
        "      else:\n",
        "        return 1\n",
        "\n",
        "    def get_news_links(self):      \n",
        "      links = []\n",
        "      news_blocks = self.soup.find_all(\"div\", {\"class\": [\"free-pr-tbl-1\",\"free-pr-tbl\"]})\n",
        "      for news_block in news_blocks:\n",
        "        news_link = news_block.find(\"a\")['href']\n",
        "        links.append(news_link)\n",
        "      return links\n",
        "\n",
        "    def get_title(self):\n",
        "      return self.soup.find(\"div\", {\"class\":\"inner-pr-title\"}).h1.text  \n",
        "\n",
        "    def get_body(self):\n",
        "      return self.soup.find(\"div\", {\"class\":\"pr-profile-tbl\"}).li.get_text() \n",
        "\n",
        "    def get_date(self):\n",
        "      return self.soup.find(\"a\", {\"class\":\"gry-links\"}).text  "
      ],
      "metadata": {
        "id": "lIfy2ntoYRRk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_all_news_links\n",
        "Function to get all the news links"
      ],
      "metadata": {
        "id": "vx63uohobDnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_news_links():\n",
        "  dates = get_all_dates_in_range()\n",
        "  main_urls = []\n",
        "  news_links = []\n",
        "  for date in dates:\n",
        "    specific_url = HUB_URL + '/' + date + '.html'\n",
        "    main_urls.append(specific_url)\n",
        "    url_object = Url(specific_url)\n",
        "    url_object.get_soup()\n",
        "    number_of_pages = url_object.get_number_of_pages()\n",
        "    news_links = news_links + url_object.get_news_links()\n",
        "    if number_of_pages > 1:\n",
        "          for x in range(2, number_of_pages + 1):\n",
        "              specific_url_with_pagination = HUB_URL + '/' + date + '_page' + str(x) +  '.html'\n",
        "              url_object_with_pagination = Url(specific_url_with_pagination)\n",
        "              url_object_with_pagination.get_soup()\n",
        "              news_links = news_links + url_object_with_pagination.get_news_links()\n",
        "              main_urls.append(specific_url_with_pagination)    \n",
        "    \n",
        "  return news_links  "
      ],
      "metadata": {
        "id": "celknVo8ki0m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### parse_news\n",
        "Function to parse through the text in the news links"
      ],
      "metadata": {
        "id": "oP4PTO_RbN_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_news(news_links):\n",
        "  news = []\n",
        "  for news_link in news_links:\n",
        "    url_object = Url(news_link)\n",
        "    url_object.get_soup()\n",
        "    news.append({\n",
        "        'date' : url_object.get_date(),\n",
        "        'title' : url_object.get_title(),\n",
        "        'body' : url_object.get_body(),\n",
        "    })\n",
        "  return news"
      ],
      "metadata": {
        "id": "FbOktwDP0ygX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.\tTrack/Store/Search\n",
        "\n",
        "\n",
        "\n",
        "*   Store the scrapped data in CSV \n",
        "*   Read the stored data and search for stock symbols\n",
        "\n"
      ],
      "metadata": {
        "id": "A1YSOddGdE2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download_csv\n",
        "Function to Download CSV containing Date Title and Body of every news article "
      ],
      "metadata": {
        "id": "BJt9r0nybdsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_csv(all_news):\n",
        "  date_range = get_date_range()\n",
        "  column_headings = [\n",
        "      'Date', \n",
        "      'Title',\n",
        "      'Body', \n",
        "      ]\n",
        "\n",
        "  file_name = 'news_articles' + '_from_' + date_range['start_date'] + '_to_' + date_range['end_date'] + '.csv'\n",
        "  with open(file_name, mode='w') as news_file:\n",
        "      news_writer = csv.writer(news_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
        "      news_writer.writerow(column_headings)\n",
        "      for news in all_news:\n",
        "        news_writer.writerow(news.values())\n",
        "  return file_name\n"
      ],
      "metadata": {
        "id": "D_qVtwr2xgCg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_stock_data\n",
        "Function that uses the Stock Symbol API to get all the trading stocks in the reuired markets\n",
        "\n",
        "We are targeting the markets of USA, Canada and India"
      ],
      "metadata": {
        "id": "qhMOlDXmdKr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_data():\n",
        "  stock_symbol_api = StockSymbol(STOCK_SYMBOL_API_KEY)\n",
        "  stock_data = []\n",
        "  for country in LIST_OF_COUNTRIES:\n",
        "    stock_data = stock_data + stock_symbol_api.get_symbol_list(market=country)[:100]\n",
        "  return stock_data"
      ],
      "metadata": {
        "id": "1UVkkvcL0ASx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_stock_symbols\n",
        "Function to return the stock symbols found in a piece of text"
      ],
      "metadata": {
        "id": "LCIVeI5ideoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_symbols(text):\n",
        "  stock_data = get_stock_data()\n",
        "  stocks_found = []\n",
        "  for stock in stock_data:\n",
        "    condition1 = \" \" + stock['symbol'].split('.')[0] + \" \" in text or \" \" + stock['shortName'].split('.')[0] + \" \" in text or \" \" + stock['longName'].split('.')[0] + \" \" in text\n",
        "    condition2 = stock['symbol'].split('.')[0] not in STOCKS_TO_IGNORE and stock['shortName'] not in STOCKS_TO_IGNORE\n",
        "    if condition1 and condition2:\n",
        "      stocks_found.append(stock)\n",
        "  return stocks_found"
      ],
      "metadata": {
        "id": "mv-5QcaGTilP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_all_stock_symbols\n",
        "Function to read each row of the stored CSV and search for the stock symbols"
      ],
      "metadata": {
        "id": "KknhUtkndiud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_stock_symbols(csv_name):\n",
        "  stocks_found = []\n",
        "  with open(csv_name) as csv_file:\n",
        "      csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "      line_count = 0\n",
        "      for row in csv_reader:\n",
        "          if line_count == 0:\n",
        "              #ignore header\n",
        "              line_count += 1\n",
        "          else:\n",
        "              stocks_found = stocks_found + get_stock_symbols(row[2])\n",
        "              if (len(stocks_found) > 2):\n",
        "                break\n",
        "  return stocks_found"
      ],
      "metadata": {
        "id": "eWiWyuqIrz2b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Retrieve Data "
      ],
      "metadata": {
        "id": "adBYiDJVP8vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_stock_price_and_volume\n",
        "\n",
        "Get the price and volume of the given ticker"
      ],
      "metadata": {
        "id": "4i7nM8xpT-6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_price_and_volume(ticker_symbol):\n",
        "  date_range = get_date_range()\n",
        "  \n",
        "  end_date = datetime.today()\n",
        "  start_date = end_date - timedelta(days=180) #6 months\n",
        "\n",
        "  data = yf.download(ticker_symbol, start_date, end_date)\n",
        "  data['Date'] = data.index\n",
        "  data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
        "  data.reset_index(drop=True, inplace=True)\n",
        "  # print(data)\n",
        "\n",
        "  data.to_csv('Stock_Data_' + ticker_symbol + '_from_' + date_range['start_date'] + '_to_' + date_range['end_date'] + '.csv')\n",
        "  return data"
      ],
      "metadata": {
        "id": "wusovIeKQD6w"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize"
      ],
      "metadata": {
        "id": "IpBDTWH8XrG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_tickers(stock_symbols):\n",
        "  ticker_search = ''\n",
        "  for stock_symbol in stock_symbols:    \n",
        "    ticker_search = ticker_search + ' ' + stock_symbol['symbol']\n",
        "  return ticker_search"
      ],
      "metadata": {
        "id": "MpfGSO_cAje8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels():\n",
        "  end_date = datetime.today()\n",
        "  start_date = end_date - timedelta(days=180)\n",
        "  plt.xlabel(start_date.strftime(\"%m/%d/%Y\") + ' - ' +  end_date.strftime(\"%m/%d/%Y\"))\n",
        "  plt.ylabel('Price of Stocks')"
      ],
      "metadata": {
        "id": "swewgF1uhRVX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def close_graph(stock_data):\n",
        "  stock_data['Close'].plot(legend= True, figsize=(13,7))\n",
        "  plt.title('Close Price')\n",
        "  labels()"
      ],
      "metadata": {
        "id": "8Kbujaja67zp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def volume_graph(stock_data):\n",
        "  stock_data['Volume'].plot(legend= True, figsize=(13,7))\n",
        "  plt.title('Volume')\n",
        "  labels()"
      ],
      "metadata": {
        "id": "y9hB643Y69Py"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_volume(stock_data):\n",
        "  volume_graph(stock_data)\n",
        "def plot_close(stock_data):  \n",
        "  close_graph(stock_data)"
      ],
      "metadata": {
        "id": "MuoGdGDYiDi1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #test\n",
        "#stock_data = get_stock_price_and_volume('AMZN TSLA AAPL')\n",
        "#plot(stock_data)\n",
        "# close_graph(stock_data)\n",
        "# volume_graph(stock_data)"
      ],
      "metadata": {
        "id": "sIE2dbfHaQuU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize\n"
      ],
      "metadata": {
        "id": "9Oohj2ZwTs1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Inspired from https://stackoverflow.com/questions/55649356/how-can-i-detect-if-trend-is-increasing-or-decreasing-in-time-series \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if the slope is a +ve value --> increasing trend\n",
        "\n",
        "    if the slope is a -ve value --> decreasing trend\n",
        "\n",
        "    if the slope is a zero value --> No trend\n"
      ],
      "metadata": {
        "id": "1xb6UM4NECQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trendline(index,data, order=1):\n",
        "    coeffs = np.polyfit(index, list(data), order)\n",
        "    slope = coeffs[-2]\n",
        "    return float(slope)"
      ],
      "metadata": {
        "id": "m2_4soT4Ue0i"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(stock_data, stock_symbols):\n",
        "\n",
        "  for stock_symbol in stock_symbols:\n",
        "    \n",
        "    idx = pd.IndexSlice\n",
        "    A = stock_data.loc[:,idx[:,'AMZN']]\n",
        "    X = A['Close'].dropna()\n",
        "    index=list(range(0,len(X)))\n",
        "    List= X.to_numpy()\n",
        "    resultent=trendline(index,List)\n",
        "\n",
        "    if (resultent > 0):\n",
        "      print(1)\n",
        "    elif(resultent < 0):\n",
        "      print(2)\n",
        "    else:\n",
        "      print(3)\n",
        "    print(resultent)   \n"
      ],
      "metadata": {
        "id": "Ua6tx2ezEBTk"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main\n",
        " The main function where the fun happens "
      ],
      "metadata": {
        "id": "cHQilZjSdrTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main() :  \n",
        "  #get news\n",
        "  all_news = parse_news(get_all_news_links())\n",
        "\n",
        "  #store news\n",
        "  csv_name = download_csv(all_news)\n",
        "\n",
        "  #search news for stocks\n",
        "  stock_symbols = get_all_stock_symbols(csv_name)\n",
        "  all_tickers_found = get_all_tickers(stock_symbols)\n",
        "  stock_data = get_stock_price_and_volume(all_tickers_found)\n",
        "  \n",
        "  #plot graphs of stocks found\n",
        "  # plot_volume(stock_data)\n",
        "  # plot_close(stock_data)\n",
        "\n",
        "  #recommend users\n",
        "  recommend(stock_data, stock_symbols)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "-T6ivPu-Yu6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}